{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "\n",
    "DATA_PATH = \"../../local_data/llamaindex_docs\"\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"**/*.md\", show_progress=True)\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = load_documents()\n",
    "# print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# from llama_index.core import set_global_handler\n",
    "\n",
    "# set_global_handler(\"deepeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/montazeran/workspace/docsherpa/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "embed_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\", api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\"\n",
    "def save_to_chroma(docs):\n",
    "    \"\"\"\n",
    "    Save the given list of Document objects to a Chroma database.\n",
    "    Args:\n",
    "    chunks (list[Document]): List of Document objects representing text chunks to save.\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Clear out the existing database directory if it exists\n",
    "    # if os.path.exists(CHROMA_PATH):\n",
    "    #   shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "    # Create a new Chroma database from the documents using OpenAI embeddings\n",
    "    db = Chroma.from_documents(\n",
    "      docs,\n",
    "      embed_model,\n",
    "      persist_directory=CHROMA_PATH\n",
    "    )\n",
    "\n",
    "  # Persist the database to disk\n",
    "    db.persist()\n",
    "    print(f\"Saved {len(docs)} docs to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_store():\n",
    "    \"\"\"\n",
    "    Function to generate vector database in chroma from documents.\n",
    "    \"\"\"\n",
    "    documents = load_documents() # Load documents from a source\n",
    "    save_to_chroma(documents) # Save the processed data to a data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:14<00:00, 62.28it/s] \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenAIEmbedding' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_data_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mgenerate_data_store\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mFunction to generate vector database in chroma from documents.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m documents \u001b[38;5;241m=\u001b[39m load_documents() \u001b[38;5;66;03m# Load documents from a source\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msave_to_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36msave_to_chroma\u001b[0;34m(docs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m  Save the given list of Document objects to a Chroma database.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m  None\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;66;03m# Clear out the existing database directory if it exists\u001b[39;00m\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;66;03m# if os.path.exists(CHROMA_PATH):\u001b[39;00m\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;66;03m#   shutil.rmtree(CHROMA_PATH)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m# Create a new Chroma database from the documents using OpenAI embeddings\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m   db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHROMA_PATH\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Persist the database to disk\u001b[39;00m\n\u001b[1;32m     23\u001b[0m   db\u001b[38;5;241m.\u001b[39mpersist()\n",
      "File \u001b[0;32m~/workspace/docsherpa/venv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/docsherpa/venv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:842\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[1;32m    837\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    838\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    839\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    840\u001b[0m         )\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/workspace/docsherpa/venv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAIEmbedding' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Settings.embed_model = embed_model\n",
    "\n",
    "# db = chromadb.PersistentClient(path=\"../../chroma_db\")\n",
    "# chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection, embed_model=embed_model)\n",
    "\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     docs, storage_context=storage_context, embed_model=embed_model\n",
    "# )\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a basic code example of creating an agent with LlamaIndex in Python. This code defines a `LlamaIndexAgent` class that can solve a task by selecting and executing tools. You can customize the tools and logic based on your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "res = chat_engine.chat(\"how can I create agent with llamaindex? show me some code example\")\n",
    "print(res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an agent with LlamaIndex, you can define a series of steps that the agent will take to solve a task. Each step involves selecting the best tool from a set of tools available to the agent. Here is a basic code example of creating an agent using LlamaIndex:\n",
      "\n",
      "```python\n",
      "class LlamaIndexAgent:\n",
      "    def __init__(self, task):\n",
      "        self.task = task\n",
      "        self.tools = []  # Define a list of tools available to the agent\n",
      "\n",
      "    def select_tool(self, step):\n",
      "        # Logic to select the best tool for the given step\n",
      "        return self.tools[step % len(self.tools)]\n",
      "\n",
      "    def execute_step(self, step):\n",
      "        tool = self.select_tool(step)\n",
      "        result = tool.execute()  # Execute the selected tool\n",
      "        return result\n",
      "\n",
      "    def solve_task(self):\n",
      "        step = 0\n",
      "        while True:\n",
      "            result = self.execute_step(step)\n",
      "            if self.task_completed(result):\n",
      "                return result\n",
      "            step += 1\n",
      "\n",
      "    def task_completed(self, result):\n",
      "        # Logic to determine if the task is completed based on the result\n",
      "        return True  # Placeholder logic for task completion\n",
      "\n",
      "# Example of creating and using a LlamaIndexAgent\n",
      "task = \"Sample task description\"\n",
      "agent = LlamaIndexAgent(task)\n",
      "result = agent.solve_task()\n",
      "print(result)\n",
      "```\n",
      "**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in res.sources:\n",
    "    print(s, end='\\n**\\n')\n",
    "len(res.sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3094"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chroma_collection.get()['ids'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
